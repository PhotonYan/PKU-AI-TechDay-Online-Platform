序号,Title,Author,Abstract,期刊/会议,方向,作者联系方式
1,FelineVerse: A Controllable Diffusion Framework for High-Fidelity Cartoon Cat Character Generation,Tong Tong,"Cartoon animal character generation has become an emerging topic in visual content creation, yet existing generative models struggle to maintain identity consistency, fine-grained stylization, and controllable expression across diverse rendering contexts. In this work, we present FelineVerse, a diffusion-based framework tailored for high-fidelity cartoon cat character synthesis. Our method introduces a dual-branch semantic prior—comprising a shape prior for body proportion and silhouette control, and a style prior for texture, color palette, and artistic abstraction. To enhance identity persistence across poses and scenes, we design a Character Embedding Encoder (CEE) that aggregates multi-view exemplars into a single latent signature, enabling cross-prompt consistency and robust generalization. We further incorporate a structure-guided generation module that leverages joint keypoints and spatial layout hints, allowing users to specify pose, composition, or expressive nuances without compromising the model’s creative flexibility. Empirically, FelineVerse achieves state-of-the-art performance on our curated CartoonCat-200 dataset, improving FID by 18.7% and identity-consistency metrics by 32.4% compared with strong diffusion baselines. Human evaluations demonstrate clear gains in style coherence, character recognizability, and user-controllable expressiveness. Our results highlight the potential of domain-specialized diffusion architectures in cartoon character generation and provide a scalable framework for broader stylized visual creation.",CatVPR,CV,tongtong@stu.pku.edu.cn
2,CatControl: Controllable Cartoon Cat Generation via Keypoint-Guided Diffusion,Xue Ni,"This work proposes CatControl, a controllable generation framework for cartoon cat images using keypoint-guided diffusion. The model incorporates 2D pose keypoints and spatial layout hints to ensure fine-grained control over body posture, facial expression, and composition. A pose–style disentanglement module stabilizes artistic appearance across varying poses. Benchmarking results show that CatControl significantly improves alignment between user-specified controls and generated outputs while maintaining visual fidelity. The approach highlights the value of structured priors in stylized character creation tasks.",CatCCV,CV,xueni@stu.pku.edu.cn
3,CatLLM: A Multimodal Language Model for Understanding and Generating Cartoon Cat Dialogue,Tong Tong,"We introduce CatLLM, a multimodal language model designed for understanding and generating dialogue for cartoon cat characters. Unlike traditional dialogue models, CatLLM integrates visual style embeddings extracted from character images, enabling consistent personality, tone, and emotional alignment across text outputs. To model expressive behaviors unique to cartoon characters, we construct a paired dataset of cat-themed utterances annotated with mood, intent, and stylized linguistic patterns. A cross-modal fusion module connects visual identity cues with textual generation, improving character consistency and emotional coherence. Experiments across dialogue generation, emotional classification, and style transfer show that CatLLM outperforms strong LLM and vision-language baselines. The model provides a scalable foundation for stylized character interaction and narrative creation.",CatCl,NLP,tongtong@pku.edu.cn